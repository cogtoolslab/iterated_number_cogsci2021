{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import requests # this is to access the stim urls from the notebook\n",
    "from IPython.display import SVG, display # need for showing stims with sketches side by side\n",
    "import base64\n",
    "import PIL\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import importlib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "# so dataframes don't get cut off in display:\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "# a way to hide the little red error warnings that show up sometimes: (https://stackoverflow.com/questions/9031783/hide-all-warnings-in-ipython)    \n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "gallery_dir = os.path.abspath(os.path.join(proj_dir,'gallery'))\n",
    "datastructures_dir = os.path.join(analysis_dir,'datastructures')\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'utils'))   \n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(x) for x in [results_dir,plot_dir,csv_dir,sketch_dir,gallery_dir,datastructures_dir]]\n",
    "\n",
    "## add utils to python path\n",
    "import sys\n",
    "if os.path.join(proj_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'utils'))\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### establish connection to mongo\n",
    "first thing you need to do is to establish an ssh tunnel (aka remote port forwarding) to the server, so that requests to the mongodb can be made \"as if\" the mongodb server is running on your local computer. Run this from the command line before you begin data analysis if you plan to fetch data from mongo:\n",
    "\n",
    "ssh -fNL 27020:127.0.0.1:27017 USER@cogtoolslab.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ssh -fNL 27020:127.0.0.1:27017 sholt@cogtoolslab.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv(os.path.join(analysis_dir,'auth.txt'), header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org'\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "import socket\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1:27017')\n",
    "db = conn['iterated_number']\n",
    "coll = db['num8_shape4']\n",
    "\n",
    "# which iteration name(s) should we use?\n",
    "iterationNames = ['run2','run3','run4','run5','run6']\n",
    "iterationName = 'run6'\n",
    "# this has previously been run1, then sandbox3, but switched to sandbox 3 for testing the url recording function\n",
    "\n",
    "## Notes to Self:\n",
    "# # If you ever want to see how many unique levels there are in mongodb coll\n",
    "# w = coll.find({'iterationName':iterationName, 'eventType':'survey'})\n",
    "# W = pd.DataFrame(w)\n",
    "# coll.distinct('eventType')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here is what one of these records looks like\n",
    "coll.find_one()\n",
    "np.save(os.path.join(datastructures_dir,\"workers_list.npy\"),coll.distinct( \"workerId\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fetch records that match our list of iterationNames\n",
    "print('Currently trying to generate clickedObj group dataframe...')\n",
    "k = coll.find({'iterationName': {'$in': iterationNames}, 'eventType':'clickedObj'})\n",
    "## create (raw, unfiltered) group dataframe containing all clickedObj \n",
    "## data from iterationNames of interest\n",
    "K = pd.DataFrame(list(k))\n",
    "print('Finished generating clickedObj group dataframe.')\n",
    "\n",
    "## now make group dataframe for stroke data\n",
    "print('Currently trying to generate stroke group dataframe...')\n",
    "t = coll.find({'iterationName': {'$in': iterationNames}, 'eventType':'stroke'})\n",
    "T = pd.DataFrame(list(t))\n",
    "print('Finished generating stroke group dataframe.')\n",
    "\n",
    "## get list of valid game IDs (i.e, subject number)\n",
    "from collections import Counter\n",
    "game_dict = Counter(K['gameid']) ## get dictionary mapping gameIDs to number of sketches \n",
    "complete_gameids = [k for (k,v) in game_dict.items() if v==32] ## get gameids that contributed exactly the right number of sketches\n",
    "\n",
    "## subset stroke/sketch dataframes by being complete AND also exclude practice\n",
    "subset = True\n",
    "if (subset and T['gameid'].nunique()!=len(complete_gameids)):\n",
    "    T = T[(T['gameid'].isin(complete_gameids))].reset_index(drop=True)\n",
    "    K = K[(K['gameid'].isin(complete_gameids))].reset_index(drop=True)\n",
    "    \n",
    "print('We have {} unique stroke records in all {} of our complete games.'.format(T.shape[0],len(complete_gameids)))\n",
    "print('We have {} unique sketch records in all {} of our complete games.'.format(K.shape[0],len(complete_gameids)))\n",
    "\n",
    "# save out to csv\n",
    "T.to_csv(os.path.join(csv_dir,'photodraw_stroke_data.csv'),index=False)\n",
    "K.to_csv(os.path.join(csv_dir,'photodraw_sketch_data.csv'),index=False)\n",
    "print('Successfully saved out our stroke/sketch data CSVs to {}.'.format(csv_dir))\n",
    "\n",
    "# changing the target url because I want it in the sketch metadata, but '/' gets read as file path, so just take suffix\n",
    "for i in K.index:\n",
    "    K['targ_s_url'][i] = K['targ_s_url'][i].split('/')[-1]\n",
    "\n",
    "## generate group dataframe and save out to file\n",
    "# importlib.reload(utils)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Now crunching some numbers and adding more useful columns to the raw dataframe...')\n",
    "D = utils.generate_dataframe(coll, complete_gameids, iterationName, csv_dir)\n",
    "print('Done processing group dataframe with lots of handy additional columns!')\n",
    "\n",
    "# Turning things that can be numeric into numeric things\n",
    "D = D.astype({'trialNum': 'float',\n",
    "              'cardinality': 'float',\n",
    "              'drawDuration': 'float',\n",
    "              'outcome': 'float',\n",
    "              'numStrokes': 'float',\n",
    "              'meanPixelIntensity': 'float',\n",
    "              'numCurvesPerSketch': 'float',\n",
    "              'numCurvesPerStroke': 'float',\n",
    "              'D1_Car': 'float',\n",
    "              'D2_Car': 'float',\n",
    "              'D3_Car': 'float'})\n",
    "\n",
    "## some additional postprocessing: add arc length information to the group dataframe \n",
    "try:\n",
    "    from bezier import curve\n",
    "    from svg.path import Path, Line, Arc, CubicBezier, QuadraticBezier, Close, parse_path\n",
    "    D = utils.GetArcLenData(D)\n",
    "except:\n",
    "    print('Something went wrong with adding arc length info to the dataframe, sorry!')\n",
    "    pass\n",
    "\n",
    "# Keep track of which quarter of the experiment the trial happened in\n",
    "D['quarter'] = np.ceil(D['trialNum']/8)\n",
    "D = D.astype({'quarter': 'float'})\n",
    "D['cardinality'] = D['cardinality'] + 1 #cardinalities are 0-indexed, which is ugly\n",
    "\n",
    "D_backup = D #we are going to exclude data from D, so might as well back it up into another variable too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## monitor how far along games-in-progress are\n",
    "all_games = K['gameid'].unique()\n",
    "num_games = len(all_games)\n",
    "print('There are a total of {} unique gameids in mongo.'.format(num_games))\n",
    "\n",
    "print('\\n')\n",
    "print('These are the games and how many trials have been completed so far:')\n",
    "for name, group in K.groupby('gameid'):\n",
    "    print('gameid: {} | number of trials : {}'.format(name, group.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: hash 'workerId' so that we do not save actual workerIDs to file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning (this code was *after* image rendering to sort out the duds. Now it has been moved to *before* image rendering so that we only generate the images that we want to analyze in the NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data out onto a CSV so we can do some analysis in R\n",
    "\n",
    "# First clean it up by removing games that we have to exclude. Get dud games manually:\n",
    "dud_games = [#\"6769-3ee1e797-2c5b-4441-8d67-5ccd1c6b9a73\",    #number; decided not to exclude because it didn't violate pre-registered criteria    \n",
    "             \"8369-76e6f73d-922a-4aca-b98a-8c96026aa48a\",    #number; excluded because of below-threshold accuracy\n",
    "             \"1372-60cdfd55-28bb-411c-b777-c51eaadee7a9\",    #shape; below-threshold accuracy\n",
    "             \"2949-1e579088-8493-4c07-873c-7bd6d00685e3\",    #shape; included pre-existing symbols\n",
    "             \"7197-6d1f3fda-040a-455c-aef0-279ba9aef053\",    #shape; included pre-existing symbols\n",
    "             \"9237-4cc76e85-9955-4cef-b03c-5c68f46321ca\",    #shape; below-threshold accuracy\n",
    "             \"1947-29382ba4-5747-456d-ba8b-276812fc1fb3\"]    #shape; below-threshold accuracy\n",
    "\n",
    "# now remove them from both D and K\n",
    "for dud in dud_games:\n",
    "    D = D[D.gameID != dud]\n",
    "    K = K[K.gameid != dud]\n",
    "\n",
    "# the names of the games we want to keep:\n",
    "kosher_games = [game for game in complete_gameids if game not in dud_games]\n",
    "\n",
    "# Export the csv. This is what the R script will look at\n",
    "D.to_csv(os.path.join(csv_dir,'iternum_group_data_{}.csv'.format(iterationName)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv(os.path.join(csv_dir,'iternum_group_data_{}.csv'.format(iterationName)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### render out all the sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "utils.render_images(K,data = 'pngString',\n",
    "                    metadata = ['gameid','intendedName','trialNum','game_condition','targ_s_url'],\n",
    "                    out_dir = sketch_dir,\n",
    "                    delimiter = '_', # used to be '_', but changed because want url in metadata and url has '_'\n",
    "                    savetargs = True)\n",
    "#                     NN=True) # why did I write this? Might be a version control mistake here somewhere..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make sketch gallery (for complete games only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "## actually render sketch gallery for each complete game\n",
    "utils.render_sketch_gallery(kosher_games,\n",
    "                            D,\n",
    "                            sketch_dir = sketch_dir,\n",
    "                            gallery_dir = gallery_dir,\n",
    "                            num_trials = 32,\n",
    "                            by_trialnum = True,\n",
    "                            show_correct = True,\n",
    "                            transpose=False,\n",
    "                            delimiter='_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show sketch galleries with target stimulus below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking visually to see if the spatial distributions of sketcher target matches the sketches\n",
    "def show_targ_and_sketch(ID,trialnum,disp=True):\n",
    "    \"\"\"\n",
    "    Just a function that plots a sketch (specified by the gameID and trial number) with its target stimulus.\n",
    "    Output of this function is the image showing both side by side.\n",
    "    \"\"\"\n",
    "    game = D[D.gameID == ID]\n",
    "    trial = game[game.trialNum == trialnum]\n",
    "    stim_url = trial['Targ_s_Url'].values[0]\n",
    "    get_stim = requests.get(stim_url)\n",
    "    stim = Image.open(BytesIO(get_stim.content))\n",
    "    \n",
    "    get_sketch = trial['png'].values[0]\n",
    "    sketch = Image.open(BytesIO(base64.b64decode(get_sketch)))\n",
    "    \n",
    "    sketch = sketch.resize((100,100))\n",
    "    stim = stim.resize((100,100))\n",
    "    \n",
    "    images = [sketch,stim]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    total_width = max(widths)\n",
    "    max_height = sum(heights)\n",
    "    whole_trial = Image.new('RGBA', (total_width, max_height),color='white')\n",
    "    y_offset = 0\n",
    "    for im in images:\n",
    "        whole_trial.paste(im, (0,y_offset))\n",
    "        y_offset += im.size[1]\n",
    "    if disp == True:\n",
    "        display(whole_trial)\n",
    "    return whole_trial\n",
    "\n",
    "def show_targs_sketches_game(ID,save=False):\n",
    "    \"\"\"\n",
    "    This function takes in a gameID and shows sketches and their targets for every trial, side by side.\n",
    "    Optionally, it will save this output into a png.\n",
    "    \"\"\"\n",
    "    whole_game = Image.new('RGBA', (3200, 200),color='white')\n",
    "    for trial_num in np.arange(1,33):\n",
    "        trial = show_targ_and_sketch(ID,trial_num,disp=False)\n",
    "        whole_game.paste(trial,(trial_num*100-100,0))\n",
    "        \n",
    "    if save == True:\n",
    "        condition = D[D.gameID == ID]['Game_Condition'].values[0]\n",
    "        fname = str(condition) + '_' + ID + \"_s_s\"\n",
    "        \n",
    "        out_dir = './sketches_stims'\n",
    "        # create the out_dir if it does not already exist\n",
    "        if not os.path.exists(out_dir): \n",
    "            os.makedirs(out_dir)\n",
    "            \n",
    "        # now save the image out to that directory\n",
    "        if not os.path.exists(os.path.join(out_dir,fname+'.png')):\n",
    "            print('Rendering…', fname + '.png') \n",
    "            whole_game.save(os.path.join(out_dir,fname+'.png'),'PNG')\n",
    "            \n",
    "    return whole_game\n",
    "\n",
    "for game_id in kosher_games:\n",
    "    print(\"Now generating sketch + stim display for \",game_id)\n",
    "    show_targs_sketches_game(game_id,save=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyze performance (accuracy and RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the accuracy of each game\n",
    "acc_table = D.groupby('gameID')['outcome'].mean().reset_index()\n",
    "acc_table['outcome'].mean()\n",
    "\n",
    "# get a one data structure for number games and one fro animal games\n",
    "df_num = D.loc[D['Game_Condition'] == 'number']\n",
    "df_aml = D.loc[D['Game_Condition'] == 'shape']\n",
    "\n",
    "# print the mean accuracy for each game condition\n",
    "acc_table_num = df_num.groupby('gameID')['outcome'].mean().reset_index()\n",
    "acc_table_aml = df_aml.groupby('gameID')['outcome'].mean().reset_index()\n",
    "\n",
    "print(\"Mean accuracy for number games was {}\".format(acc_table_num['outcome'].mean()))\n",
    "print(\"Mean accuracy for shape games was {}\".format(acc_table_aml['outcome'].mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for 1YPaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1 was just showing written number systems. No quantitative data\n",
    "# Figure 3 was showing qualitative data, i.e. sketches and stimuli. No quantitative\n",
    "\n",
    "# First want to generate dataframes under specific restrictions to look at\n",
    "# just number games or just shape games\n",
    "df_num = D.loc[D['Game_Condition'] == 'number']\n",
    "df_aml = D.loc[D['Game_Condition'] == 'shape']\n",
    "\n",
    "# just games that are number or shape, and a specific quarter of those games\n",
    "dn1 = df_num.loc[df_num['quarter'] == 1.0]\n",
    "dn2 = df_num.loc[df_num['quarter'] == 2.0]\n",
    "dn3 = df_num.loc[df_num['quarter'] == 3.0]\n",
    "dn4 = df_num.loc[df_num['quarter'] == 4.0]\n",
    "\n",
    "da1 = df_aml.loc[df_aml['quarter'] == 1.0]\n",
    "da2 = df_aml.loc[df_aml['quarter'] == 2.0]\n",
    "da3 = df_aml.loc[df_aml['quarter'] == 3.0]\n",
    "da4 = df_aml.loc[df_aml['quarter'] == 4.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2: DVs over IVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2 produced as follows, showing each naive measure over cardinality & animal\n",
    "\n",
    "# set what data we want to plot; this can be any trial block, or all blocks\n",
    "num_data = df_num\n",
    "aml_data = df_aml\n",
    "\n",
    "# overall figure parameters\n",
    "graph_size = (5,2)\n",
    "card_fig = plt.figure(\"By Cardinality\",figsize=(10,10))\n",
    "card_fig.suptitle(\"Figure 2 – DVs by Stimulus Feature\")\n",
    "# card_fig.suptitle(\"        \")\n",
    "\n",
    "ax1 = card_fig.add_subplot(4,2,1)\n",
    "ax2 = card_fig.add_subplot(4,2,2)\n",
    "ax3 = card_fig.add_subplot(4,2,3)\n",
    "ax4 = card_fig.add_subplot(4,2,4)\n",
    "ax5 = card_fig.add_subplot(4,2,5)\n",
    "ax6 = card_fig.add_subplot(4,2,6)\n",
    "ax7 = card_fig.add_subplot(4,2,7)\n",
    "ax8 = card_fig.add_subplot(4,2,8)\n",
    "\n",
    "## the legend, if ever we want to put it in\n",
    "number_patch = mpatches.Patch(color='#25B1F7', label='Number Games')\n",
    "animal_patch = mpatches.Patch(color='#B92BCF', label='Animal Games')\n",
    "plt.legend(handles=[number_patch, animal_patch])\n",
    "\n",
    "\n",
    "\n",
    "# for all the odd subplots, plot out DVs over cardinality\n",
    "\n",
    "# plt.figure(\"Ink over Cardinality\",figsize=graph_size)\n",
    "sns.pointplot(data=num_data, x='cardinality', y='meanPixelIntensity',color='#25B1F7',markers='.',ax=ax1)\n",
    "sns.pointplot(data=aml_data, x='cardinality', y='meanPixelIntensity',color='#B92BCF',markers='.',ax=ax1)\n",
    "# plt.title(\"Ink by Cardinality\")\n",
    "# plt.ylabel(\"Ink\")\n",
    "# plt.xlabel(\"\")\n",
    "# plt.xticks([])\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"Strokes over Cardinality\",figsize=graph_size)\n",
    "sns.pointplot(data=num_data, x='cardinality', y='numStrokes',color='#25B1F7',markers='.',ax=ax3)\n",
    "sns.pointplot(data=aml_data, x='cardinality', y='numStrokes',color='#B92BCF',markers='.',ax=ax3)\n",
    "# plt.title(\"Strokes by Cardinality\")\n",
    "# plt.ylabel(\"Strokes\")\n",
    "# plt.xlabel(\"\")\n",
    "# plt.xticks([])\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"Sketch Time over Cardinality\",figsize=graph_size)\n",
    "sns.pointplot(data=num_data, x='cardinality', y='drawDuration',color='#25B1F7',markers='.',ax=ax5)\n",
    "sns.pointplot(data=aml_data, x='cardinality', y='drawDuration',color='#B92BCF',markers='.',ax=ax5)\n",
    "# plt.title(\"Sketch Time by Cardinality\")\n",
    "# plt.ylabel(\"Sketch Time\")\n",
    "# plt.xlabel(\"\")\n",
    "# plt.xticks([])\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"Accuracy over Cardinality\",figsize=graph_size)\n",
    "sns.pointplot(data=num_data, x='cardinality', y='outcome',color='#25B1F7',markers='.',ax=ax7)\n",
    "sns.pointplot(data=aml_data, x='cardinality', y='outcome',color='#B92BCF',markers='.',ax=ax7)\n",
    "# plt.title(\"Accuracy by Cardinality\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.xlabel(\"Cardinality\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for all the even subplots, plot out DVs over animal\n",
    "\n",
    "# plt.figure(\"Ink over Animal Type\",figsize=graph_size)\n",
    "sns.pointplot(data=num_data, x='category', y='meanPixelIntensity',color='#25B1F7',markers='.',ax=ax2)\n",
    "sns.pointplot(data=aml_data, x='category', y='meanPixelIntensity',color='#B92BCF',markers='.',ax=ax2)\n",
    "# plt.title(\"Ink by Animal Type\")\n",
    "# plt.ylabel(\"Ink\")\n",
    "# plt.xlabel(\"\")\n",
    "# plt.xticks([])\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"Strokes over Animal Type\",figsize=graph_size)\n",
    "sns.pointplot(data=num_data, x='category', y='numStrokes',color='#25B1F7',markers='.',ax=ax4)\n",
    "sns.pointplot(data=aml_data, x='category', y='numStrokes',color='#B92BCF',markers='.',ax=ax4)\n",
    "# plt.title(\"Strokes by Animal Type\")\n",
    "# plt.ylabel(\"Strokes\")\n",
    "# plt.xlabel(\"\")\n",
    "# plt.xticks([])\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"Sketch Time over Animal Type\",figsize=graph_size)\n",
    "sns.pointplot(data=num_data, x='category', y='drawDuration',color='#25B1F7',markers='.',ax=ax6)\n",
    "sns.pointplot(data=aml_data, x='category', y='drawDuration',color='#B92BCF',markers='.',ax=ax6)\n",
    "# plt.title(\"Sketch Time by Animal Type\")\n",
    "# plt.ylabel(\"Sketch Time\")\n",
    "# plt.xlabel(\"\")\n",
    "# plt.xticks([])\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(\"Accuracy over Animal Type\",figsize=graph_size)\n",
    "sns.pointplot(data=num_data, x='category', y='outcome',color='#25B1F7',markers='.',ax=ax8)\n",
    "sns.pointplot(data=aml_data, x='category', y='outcome',color='#B92BCF',markers='.',ax=ax8)\n",
    "# plt.title(\"Accuracy by Animal Type\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.xlabel(\"Animal Type\")\n",
    "\n",
    "# Set the labels, ticks, and limits (note: limits are set to accommodate data averaged across blocks\n",
    "# individual block data goes beyond the y limits set below)\n",
    "ax1.set_ylabel(\"Ink\")\n",
    "ax3.set_ylabel(\"Strokes\")\n",
    "ax5.set_ylabel(\"Time\")\n",
    "ax7.set_ylabel(\"Accuracy\")\n",
    "ax2.set_ylabel(\"\")\n",
    "ax4.set_ylabel(\"\")\n",
    "ax6.set_ylabel(\"\")\n",
    "ax8.set_ylabel(\"\")\n",
    "ax1.set_yticks([])\n",
    "ax3.set_yticks([])\n",
    "ax5.set_yticks([])\n",
    "ax7.set_yticks([])\n",
    "\n",
    "\n",
    "ax1.set_xlabel(\"\")\n",
    "ax2.set_xlabel(\"\")\n",
    "ax3.set_xlabel(\"\")\n",
    "ax4.set_xlabel(\"\")\n",
    "ax5.set_xlabel(\"\")\n",
    "ax6.set_xlabel(\"\")\n",
    "ax7.set_xlabel(\"Cardinality\")\n",
    "ax8.set_xlabel(\"Shape\")\n",
    "\n",
    "\n",
    "ax1.set_xticks([])\n",
    "ax2.set_xticks([])\n",
    "ax3.set_xticks([])\n",
    "ax4.set_xticks([])\n",
    "ax5.set_xticks([])\n",
    "ax6.set_xticks([])\n",
    "ax7.set_xticklabels([1,2,3,4,5,6,7,8])\n",
    "ax8.set_xticklabels(['Rabbit','Bear','Deer','Owl'])\n",
    "\n",
    "ax1.set_ylim([0, .06])\n",
    "ax2.set_ylim([0, .06])\n",
    "ax3.set_ylim([1, 10])\n",
    "ax4.set_ylim([1, 10])\n",
    "ax5.set_ylim([1, 10])\n",
    "ax6.set_ylim([1, 10])\n",
    "ax7.set_ylim([0, 1])\n",
    "ax8.set_ylim([0, 1])\n",
    "\n",
    "ax2.yaxis.tick_right()\n",
    "ax4.yaxis.tick_right()\n",
    "ax6.yaxis.tick_right()\n",
    "ax8.yaxis.tick_right()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4: Correlations over Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations by trial number (this does not make it into figure 4, but is interesting)\n",
    "DV = 'numStrokes' # 'outcome', 'drawDuration', 'numStrokes', 'meanPixelIntensity'\n",
    "num_corr_trials = []\n",
    "aml_corr_trials = []\n",
    "\n",
    "def corr_confint(corrcoef,N,tc=1.96):\n",
    "    sr = np.sqrt((1-corrcoef**2)/(N-2))\n",
    "    return sr*tc\n",
    "\n",
    "for trialnum in np.arange(1,33):\n",
    "    num_trial = df_num.loc[df_num['trialNum'] == trialnum]\n",
    "    aml_trial = df_aml.loc[df_aml['trialNum'] == trialnum]\n",
    "    num_corr_trial = stats.pearsonr(num_trial['cardinality'], num_trial[DV])[0]\n",
    "    aml_corr_trial = stats.pearsonr(aml_trial['cardinality'], aml_trial[DV])[0]\n",
    "    num_corr_trials.append(num_corr_trial)\n",
    "    aml_corr_trials.append(aml_corr_trial)\n",
    "    #num_confints.append()\n",
    "    \n",
    "    \n",
    "num_corr_trials = np.array(num_corr_trials)\n",
    "aml_corr_trials = np.array(aml_corr_trials)\n",
    "    \n",
    "num_confints = corr_confint(num_corr_trials, len(np.unique(df_num['gameID'])))\n",
    "aml_confints = corr_confint(aml_corr_trials, len(np.unique(df_aml['gameID'])))\n",
    "\n",
    "plt.figure(\"Correlations (line chart)\")\n",
    "plt.title(\"Correlation of Stroke Count and Cardinality over Trials\")\n",
    "plt.plot(np.arange(1,33),32*[0],color='black',alpha = .75)\n",
    "plt.plot(np.arange(1,33),num_corr_trials,color='#25B1F7')\n",
    "plt.plot(np.arange(1,33),aml_corr_trials,color='#B92BCF')\n",
    "plt.fill_between(np.arange(1,33), (num_corr_trials-num_confints), (num_corr_trials+num_confints), color='b', alpha=.1)   \n",
    "plt.fill_between(np.arange(1,33), (aml_corr_trials-aml_confints), (aml_corr_trials+aml_confints), color='m', alpha=.1)    \n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.xlabel(\"Trial #\")\n",
    "plt.show\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations by block number\n",
    "DV = 'numStrokes' # 'outcome', 'drawDuration', 'numStrokes', 'meanPixelIntensity'\n",
    "num_corr_blocks = []\n",
    "aml_corr_blocks = []\n",
    "\n",
    "for blocknum in np.arange(1,5):\n",
    "    num_block = df_num.loc[df_num['quarter'] == blocknum]\n",
    "    aml_block = df_aml.loc[df_aml['quarter'] == blocknum]\n",
    "    num_corr_block = stats.pearsonr(num_block['cardinality'], num_block[DV])[0]\n",
    "    aml_corr_block = stats.pearsonr(aml_block['cardinality'], aml_block[DV])[0]\n",
    "    num_corr_blocks.append(num_corr_block)\n",
    "    aml_corr_blocks.append(aml_corr_block)\n",
    "    \n",
    "    \n",
    "num_corr_blocks = np.array(num_corr_blocks)\n",
    "aml_corr_blocks = np.array(aml_corr_blocks)\n",
    "\n",
    "#make sure this is the right way to do N samples - it's total trials, so 8 per block times number of games\n",
    "num_confints = corr_confint(num_corr_blocks, 8*len(np.unique(df_num['gameID'])))\n",
    "aml_confints = corr_confint(aml_corr_blocks, 8*len(np.unique(df_aml['gameID'])))\n",
    "\n",
    "plt.figure(\"Correlations (line chart)\")\n",
    "plt.title(\"Correlation of Accuracy and Cardinality over Blocks\")\n",
    "plt.plot(np.arange(1,5),4*[0],color='black',alpha = .5,linestyle='--')\n",
    "plt.plot(np.arange(1,5),num_corr_blocks,color='#25B1F7')\n",
    "plt.plot(np.arange(1,5),aml_corr_blocks,color='#B92BCF')\n",
    "plt.fill_between(np.arange(1,5), (num_corr_blocks-num_confints), (num_corr_blocks+num_confints), color='#25B1F7', alpha=.1)   \n",
    "plt.fill_between(np.arange(1,5), (aml_corr_blocks-aml_confints), (aml_corr_blocks+aml_confints), color='#B92BCF', alpha=.1)    \n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.xlabel(\"Block #\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for CogSci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colours: number #25B1F7; shape #B92BCF\n",
    "# Fig 1 straightforward accuracy measures for each condition\n",
    "num_data = df_num\n",
    "aml_data = df_aml\n",
    "\n",
    "def get_confint(df):\n",
    "    \"\"\"Takes a df already with columns ['Factors','mean','count','std'] \"\"\"\n",
    "    new_df = df\n",
    "    ci95_hi = []\n",
    "    ci95_lo = []\n",
    "    for i in new_df.index:\n",
    "        m, c, s = new_df.loc[i]\n",
    "        ci95_hi.append(m + 1.96*s/math.sqrt(c))\n",
    "        ci95_lo.append(m - 1.96*s/math.sqrt(c))\n",
    "    new_df['ci95_hi'] = ci95_hi\n",
    "    new_df['ci95_lo'] = ci95_lo\n",
    "    return new_df\n",
    "\n",
    "acc_DF = get_confint(pd.DataFrame(D.groupby(['Game_Condition'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "subject_acc = pd.DataFrame(D.groupby(['Game_Condition','gameID'])['outcome'].mean()).reset_index()\n",
    "\n",
    "fig , (ax1,ax2)= plt.subplots(1,2,figsize=(16,4),gridspec_kw={'width_ratios': [1, 2]})\n",
    "# fig.suptitle(\"Accuracy by Game Condition\")\n",
    "# ax1 = fig.add_subplot(1,2,1)\n",
    "\n",
    "ax1.set_title(\"Accuracy by Game Condition\")\n",
    "ax1.bar(acc_DF.reset_index()['Game_Condition'],\n",
    "        height=acc_DF['mean'],\n",
    "        width=.8,\n",
    "        yerr=[acc_DF['ci95_hi']-acc_DF['mean'], acc_DF['mean']-acc_DF['ci95_lo']],\n",
    "        capsize=4)\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_xlabel(\"Condition\")\n",
    "\n",
    "\n",
    "num_acc_trial_DF = get_confint(pd.DataFrame(df_num.groupby(['trialNum'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "aml_acc_trial_DF = get_confint(pd.DataFrame(df_aml.groupby(['trialNum'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "\n",
    "# ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.errorbar(range(len(num_acc_trial_DF)),num_acc_trial_DF['mean'],c='#25B1F7',\n",
    "             yerr=num_acc_trial_DF['ci95_hi']-num_acc_trial_DF['mean'])\n",
    "\n",
    "ax2.errorbar(range(len(aml_acc_trial_DF)),aml_acc_trial_DF['mean'],c='#B92BCF',\n",
    "             yerr=aml_acc_trial_DF['ci95_hi']-aml_acc_trial_DF['mean'])\n",
    "\n",
    "ax2.set_title(\"Accuracy over Trials\")\n",
    "\n",
    "ax2.set_ylim([0,1])\n",
    "ax2.set_ylabel(\"\")\n",
    "ax2.set_yticks([])\n",
    "ax2.set_xlabel(\"Trial\")\n",
    "\n",
    "ax1.get_children()[1].set_color((0,0,0,0))\n",
    "ax1.get_children()[2].set_color((0,0,0,0))\n",
    "ax1.get_children()[1].set_edgecolor('#7DCCF4')\n",
    "ax1.get_children()[2].set_edgecolor('#BD83C7')\n",
    "\n",
    "\n",
    "num_subject_acc = np.array(subject_acc[subject_acc['Game_Condition']=='number']['outcome'])\n",
    "aml_subject_acc = np.array(subject_acc[subject_acc['Game_Condition']=='shape']['outcome'])\n",
    "ax1.scatter(0 + np.random.random(num_subject_acc.size) * .03 - .01, num_subject_acc, color='k',s=2)\n",
    "ax1.scatter(1 + np.random.random(aml_subject_acc.size) * .03 - .01, aml_subject_acc, color='k',s=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do only stroke count here\n",
    "str_DF = get_confint(pd.DataFrame(D.groupby(['Game_Condition'])['numStrokes'].agg(['mean', 'count', 'std'])))\n",
    "\n",
    "num_str_trial_DF = get_confint(pd.DataFrame(df_num.groupby(['cardinality'])['numStrokes'].agg(['mean', 'count', 'std'])))\n",
    "aml_str_trial_DF = get_confint(pd.DataFrame(df_aml.groupby(['cardinality'])['numStrokes'].agg(['mean', 'count', 'std'])))\n",
    "\n",
    "numgames_str_trial_DF = get_confint(pd.DataFrame(df_num.groupby(['gameID','trialNum'])['numStrokes'].agg(['mean', 'count', 'std'])))\n",
    "amlgames_str_trial_DF = get_confint(pd.DataFrame(df_aml.groupby(['gameID','trialNum'])['numStrokes'].agg(['mean', 'count', 'std'])))\n",
    "\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(16,4),sharey=True)\n",
    "# fig.suptitle(\"Stroke Count by Condition (Total & Over Time)\")\n",
    "# ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.set_title(\"Stroke Count by Game Condition\")\n",
    "ax1.bar(str_DF.reset_index()['Game_Condition'],\n",
    "       height=str_DF['mean'],\n",
    "       yerr=[str_DF['ci95_hi']-str_DF['mean'], str_DF['mean']-str_DF['ci95_lo']],\n",
    "       capsize=4)\n",
    "\n",
    "ax1.set_ylabel(\"Number of Strokes\")\n",
    "ax1.set_xlabel(\"Condition\")\n",
    "\n",
    "\n",
    "# ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.errorbar(range(len(num_str_trial_DF)),num_str_trial_DF['mean'],c='#25B1F7',\n",
    "             yerr=num_str_trial_DF['ci95_hi']-num_str_trial_DF['mean'])\n",
    "\n",
    "ax2.errorbar(range(len(aml_str_trial_DF)),aml_str_trial_DF['mean'],c='#B92BCF',\n",
    "             yerr=aml_str_trial_DF['ci95_hi']-aml_str_trial_DF['mean'])\n",
    "\n",
    "ax2.set_title(\"Stroke Count over Trials\")\n",
    "# ax2.set_ylabel(\"\")\n",
    "# ax2.set_yticks([])\n",
    "# ax2.yaxis.tick_right()\n",
    "ax2.set_xlabel(\"Cardinality\")\n",
    "\n",
    "ax1.get_children()[1].set_color('#7DCCF4')\n",
    "ax1.get_children()[2].set_color('#BD83C7')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RT isn't really RT, it's actually drawing time. STR is stroke count\n",
    "RTs = get_confint(pd.DataFrame(D.groupby(['Game_Condition'])['drawDuration'].agg(['mean', 'count', 'std'])))\n",
    "INK = get_confint(pd.DataFrame(D.groupby(['Game_Condition'])['meanPixelIntensity'].agg(['mean', 'count', 'std'])))\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(10,4))\n",
    "ax1.set_title(\"Drawing Time by Game Condition\")\n",
    "ax1.bar(RTs.reset_index()['Game_Condition'],\n",
    "       height=RTs['mean'],\n",
    "       yerr=[RTs['ci95_hi']-RTs['mean'], RTs['mean']-RTs['ci95_lo']],\n",
    "       capsize=4)\n",
    "ax1.get_children()[1].set_color('#7DCCF4')\n",
    "ax1.get_children()[2].set_color('#BD83C7')\n",
    "\n",
    "ax2.set_title(\"Mean Pixel Intensity by Game Condition\")\n",
    "ax2.bar(INK.reset_index()['Game_Condition'],\n",
    "       height=INK['mean'],\n",
    "       yerr=[INK['ci95_hi']-INK['mean'], INK['mean']-INK['ci95_lo']],\n",
    "       capsize=4)\n",
    "ax2.get_children()[1].set_color('#7DCCF4')\n",
    "ax2.get_children()[2].set_color('#BD83C7')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure for CogSci\n",
    "\n",
    "fig , (ax1,ax2)= plt.subplots(1,2,figsize=(12,4),gridspec_kw={'width_ratios': [1, 3]})\n",
    "# fig.suptitle(\"Accuracy by Game Condition\")\n",
    "# ax1 = fig.add_subplot(1,2,1)\n",
    "\n",
    "# ax1.set_title(\"Accuracy by Game Condition\")\n",
    "\n",
    "ax1.bar(acc_DF.reset_index()['Game_Condition'],\n",
    "        height=acc_DF['mean'],\n",
    "        width=.8,\n",
    "        yerr=[acc_DF['ci95_hi']-acc_DF['mean'], acc_DF['mean']-acc_DF['ci95_lo']],\n",
    "        capsize=4)\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_xlabel(\"Condition\")\n",
    "\n",
    "num_acc_trial_DF = get_confint(pd.DataFrame(df_num.groupby(['trialNum'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "aml_acc_trial_DF = get_confint(pd.DataFrame(df_aml.groupby(['trialNum'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "\n",
    "\n",
    "\n",
    "ax2.errorbar(range(1,len(num_str_trial_DF)+1),num_str_trial_DF['mean'],c='#25B1F7',\n",
    "             yerr=num_str_trial_DF['ci95_hi']-num_str_trial_DF['mean'],\n",
    "             capsize=6)\n",
    "\n",
    "ax2.errorbar(range(1,len(aml_str_trial_DF)+1),aml_str_trial_DF['mean'],c='#B92BCF',\n",
    "             yerr=aml_str_trial_DF['ci95_hi']-aml_str_trial_DF['mean'],\n",
    "             capsize=6)\n",
    "\n",
    "ax2.legend(('Number Games', 'Shape Games'))\n",
    "# to plot accuracy over cardinality\n",
    "# acc_by_card_num = get_confint(pd.DataFrame(df_num.groupby(['gameID','cardinality'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "# acc_by_card_aml\n",
    "\n",
    "# ax2.set_title(\"Stroke Count over Trials\")\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_xlabel(\"Cardinality\")\n",
    "ax2.set_ylabel(\"Stroke Count\")\n",
    "\n",
    "ax1.get_children()[1].set_color((0,0,0,0))\n",
    "ax1.get_children()[2].set_color((0,0,0,0))\n",
    "ax1.get_children()[1].set_edgecolor('#7DCCF4')\n",
    "ax1.get_children()[2].set_edgecolor('#BD83C7')\n",
    "\n",
    "\n",
    "# show points as either subject accuracies, or cardinality / animals. If we want by subjects:\n",
    "num_subject_acc = np.array(subject_acc[subject_acc['Game_Condition']=='number']['outcome'])\n",
    "aml_subject_acc = np.array(subject_acc[subject_acc['Game_Condition']=='shape']['outcome'])\n",
    "# and if we want by cardinality / animal:\n",
    "cardinality_acc = np.array(pd.DataFrame(D[D['Game_Condition']=='number'].groupby(['cardinality'])['outcome'].mean()).reset_index()['outcome'])\n",
    "animal_acc = np.array(pd.DataFrame(D[D['Game_Condition']=='shape'].groupby(['category'])['outcome'].mean()).reset_index()['outcome'])\n",
    "\n",
    "ax1.scatter(0 + np.random.random(num_subject_acc.size) * .03, num_subject_acc, color='#7DCCF4',s=16,alpha=.6)\n",
    "ax1.scatter(1 + np.random.random(aml_subject_acc.size) * .03, aml_subject_acc, color='#BD83C7',s=16,alpha=.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('../results/plots/acc_stroke.pdf')\n",
    "\n",
    "# https://stackoverflow.com/questions/51027717/pyplot-bar-charts-with-individual-data-points/51032760\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot any old thing over any other old thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# groupby: trialNum, quarter, Game_Condition\n",
    "# outcome, numStrokes, meanPixelIntensity, drawDuration\n",
    "\n",
    "num_overtime = get_confint(pd.DataFrame(df_num.groupby(['quarter'])['numStrokes'].agg(['mean', 'count', 'std'])))\n",
    "aml_overtime = get_confint(pd.DataFrame(df_aml.groupby(['quarter'])['numStrokes'].agg(['mean', 'count', 'std'])))\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(range(len(num_overtime)),num_overtime['mean'],c='#25B1F7',\n",
    "             yerr=num_overtime['ci95_hi']-num_overtime['mean'])\n",
    "\n",
    "plt.errorbar(range(len(aml_overtime)),aml_overtime['mean'],c='#B92BCF',\n",
    "             yerr=aml_overtime['ci95_hi']-aml_overtime['mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
